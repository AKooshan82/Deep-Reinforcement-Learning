{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G29aFzYJF4Tt"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img src=\"https://www.sharif.ir/documents/20124/0/logo-fa-IR.png/4d9b72bc-494b-ed5a-d3bb-e7dfd319aec8?t=1609608338755\" alt=\"Logo\" width=\"200\">\n",
        "    <p><b> Reinforcement Learning Course, Dr. Rohban</b></p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDCIkmkF4Tv"
      },
      "source": [
        "*Full Name:Amir Kooshan Fattah Hesari*\n",
        "\n",
        "*Student Number:401102191*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBaiqMVHM2bP"
      },
      "source": [
        "# Random Network Distillation (RND) with PPO - Homework Project\n",
        "\n",
        "  \n",
        "\n",
        "---\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "## 1. Introduction: Random Network Distillation (RND)\n",
        "\n",
        "A common way of doing exploration is to visit states with a large prediction error of some quantity, for instance, the TD error or even random functions.  \n",
        "The RND algorithm ([Exploration by Random Network Distillation](https://arxiv.org/abs/1810.12894)) aims at encouraging exploration by asking the exploration policy to more frequently undertake transitions where the prediction error of a random neural network function is high.\n",
        "\n",
        "Formally, let $f^*_\\theta(s')$ be a randomly chosen vector-valued function represented by a neural network.  \n",
        "RND trains another neural network, $\\hat{f}_\\phi(s')$, to match the predictions of $f^*_\\theta(s')$ under the distribution of datapoints in the buffer, as shown below:\n",
        "\n",
        "$$\n",
        "\\phi^* = \\arg\\min_\\phi \\mathbb{E}_{s,a,s'\\sim\\mathcal{D}} \\left[ \\left\\| \\hat{f}_\\phi(s') - f^*_\\theta(s') \\right\\| \\right]\n",
        "$$\n",
        "\n",
        "If a transition $(s, a, s')$ is in the distribution of the data buffer, the prediction error $\\mathcal{E}_\\phi(s')$ is expected to be small.  \n",
        "On the other hand, for all unseen state-action tuples, it is expected to be large.\n",
        "\n",
        "In practice, RND uses two critics:\n",
        "- an exploitation critic $Q_R(s,a)$, which estimates returns based on the true rewards,\n",
        "- and an exploration critic $Q_E(s,a)$, which estimates returns based on the exploration bonuses.\n",
        "\n",
        "To stabilize training, prediction errors are normalized before being used.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What You Will Implement\n",
        "\n",
        "  \n",
        "\n",
        "You will implement the missing core components of Random Network Distillation (RND) combined with a Proximal Policy Optimization (PPO) agent inside the MiniGrid environment.\n",
        "\n",
        "  \n",
        "\n",
        "Specifically, you will:\n",
        "\n",
        "  \n",
        "\n",
        "- Complete the architecture of TargetModel and PredictorModel.\n",
        "\n",
        "  \n",
        "\n",
        "- Complete the initialization of weights for these models.\n",
        "\n",
        "  \n",
        "\n",
        "- Implement the intrinsic reward calculation (prediction error).\n",
        "\n",
        "  \n",
        "\n",
        "- Implement the RND loss calculation.\n",
        "\n",
        "  \n",
        "\n",
        "You will complete TODO sections inside two main files:\n",
        "\n",
        "  \n",
        "\n",
        "    Core/ppo_rnd_agent.py\n",
        "    Core/model.py\n",
        "\n",
        "  \n",
        "\n",
        "---\n",
        "\n",
        "  \n",
        "\n",
        "## 3. Project Structure\n",
        "\n",
        "\n",
        "```\n",
        "RND_PPO_Project/\n",
        " ├── main.py               # Main training loop and evaluation\n",
        " ├──requirements.txt       # Python dependencies               \n",
        " ├── Core/\n",
        " │    └── ppo_rnd_agent.py         # Agent logic (policy + RND + training)\n",
        " │    └── model.py         # Model architectures (policy, predictor, target)\n",
        " ├── Common/\n",
        " │    ├── config.py        # Hyperparameters and argument parsing\n",
        " │    ├── utils.py         # Utilities (normalization, helper functions)\n",
        " │    ├── logger.py        # Tensorboard logger\n",
        " │    └── play.py          # Evaluation / Play script\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Modules Explanation\n",
        "\n",
        "| Module        | Description |\n",
        "|---------------|-------------|\n",
        "| `ppo_rnd_agent.py`    | **Core agent logic.** This file contains the PPO algorithm implementation and also handles the RND intrinsic reward mechanism. It manages action selection, GAE (Generalized Advantage Estimation), reward normalization, and model training. <br>➡️ You will modify this file to implement the intrinsic reward and RND loss functions. |\n",
        "| `model.py`    | **Neural network architectures.** This defines the structure of the policy network (used for action selection) and the two RND networks — Target and Predictor. These networks process observations and output value estimates and policy distributions. <br>➡️ You will define the structure of the `TargetModel` and `PredictorModel` classes here and implement proper initialization. |\n",
        "| `utils.py`    | **Support utilities.** This includes helper functions like setting random seeds for reproducibility, maintaining running mean and variance for normalization, and a few decorators. It helps the rest of the codebase stay clean and modular. |\n",
        "| `config.py`   | **Experiment settings.** It defines all training hyperparameters (learning rate, batch size, gamma, etc.) and parses command-line flags such as `--train_from_scratch` or `--do_test`. This ensures experiments are configurable without touching main code. |\n",
        "| `logger.py`   | **Logging training metrics.** Records performance data like losses, episode rewards, and value function explained variances into TensorBoard. This helps you visually inspect whether the agent is learning or not. |\n",
        "| `play.py`     | **Evaluation module.** This file runs a trained agent in the environment without further learning. It resets the environment, feeds observations through the trained policy, and executes actions until the episode terminates. |\n",
        "| `runner.py`     | **Parallel environment interaction.** Runs a Gym environment in a separate process using torch.multiprocessing. It communicates with the main process to exchange observations and actions, enabling parallel experience collection. Supports episode reset and optional rendering. |\n",
        "| `main.py`     | **Project entry point.** Orchestrates the full experiment — sets up environment, models, logger, and executes training or testing depending on the flag. This is where everything comes together. |\n",
        "\n",
        "---\n",
        "\n",
        "## 5. TODO Parts (Your Tasks)\n",
        "\n",
        "You must complete the following parts:\n",
        "\n",
        "| File | TODO Description |\n",
        "| :--- | :--- |\n",
        "| `Core/model.py` | Implement the architecture of `TargetModel` and `PredictorModel`. |\n",
        "| `Core/model.py` | Implement `_init_weights()` method for proper initialization. |\n",
        "| `Core/ppo_rnd_agent.py` | Implement `calculate_int_rewards()` to compute intrinsic rewards. |\n",
        "| `Core/ppo_rnd_agent.py` | Implement `calculate_rnd_loss()` to compute predictor training loss. |\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho_lAcI7F4Tv"
      },
      "source": [
        "# Setup Code\n",
        "Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n",
        "\n",
        "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UTx3_X1zF4Tw"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkR7h2lPF4Tw"
      },
      "source": [
        "#### In the following cell you are going to direct to your gooledrive if you are using GooleColab which is preferable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY7wnz1YGS5z",
        "outputId": "8ffe0f5d-56ff-4fb3-82d4-5ba0dc0434f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['HW10_RND.ipynb', 'main.py', 'requirements.txt', 'Common', 'Core', 'Models', 'Logs']\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# . Moount Google Drive\n",
        "# ----------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Go the Project directory\n",
        "# ----------------------------\n",
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
        "# Example: If you create a 2020FA folder and put all the files under A1 folder, then '2020FA/A1'\n",
        "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '2020FA/A1'\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE =\"Task 2 Random Network Distillation\"\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
        "os.chdir(GOOGLE_DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA-iCbPSj5rW"
      },
      "source": [
        "\n",
        "## 1. Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cj6IeGRij9D2",
        "outputId": "a50b1e3e-366e-4810-b254-c11c37fd6ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: opencv_contrib_python>=4.4.0.44 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: minigrid in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.50.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from minigrid->-r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: pygame>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from minigrid->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->minigrid->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.1->minigrid->-r requirements.txt (line 5)) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->-r requirements.txt (line 4)) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKK1I8xkQ-gX"
      },
      "source": [
        "\n",
        "## 2. Student Instructions (Reminder)\n",
        "\n",
        "> Please open and edit the following files:\n",
        "- `Core/ppo_rnd_agent.py`\n",
        "- `Core/model.py`\n",
        "\n",
        "> Specifically, look for `TODO` markers in the code and complete the necessary parts.\n",
        "\n",
        "After you have filled in the missing parts, you can proceed to train the agent.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F01w4apP5oo"
      },
      "source": [
        "## 3. Train the agent from scratch:\n",
        "\n",
        "Now that you've completed the TODOs, let's train your agent!\n",
        "This will launch the main script with training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42IgzWrukAjM",
        "outputId": "037d3e8a-75b6-422c-d0a0-e9b20b278f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-11 22:03:45.276262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749679425.323998  102530 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749679425.338422  102530 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-11 22:03:45.395310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "Configuration:\n",
            "  n_workers: 2\n",
            "  interval: 50\n",
            "  do_test: False\n",
            "  render: False\n",
            "  train_from_scratch: True\n",
            "  env_name: MiniGrid-Empty-5x5-v0\n",
            "  state_shape: (3, 7, 7)\n",
            "  obs_shape: (3, 7, 7)\n",
            "  total_rollouts_per_env: 10000\n",
            "  max_frames_per_episode: 200\n",
            "  rollout_length: 128\n",
            "  n_epochs: 4\n",
            "  n_mini_batch: 4\n",
            "  lr: 0.00025\n",
            "  ext_gamma: 0.99\n",
            "  int_gamma: 0.99\n",
            "  lambda: 0.95\n",
            "  clip_range: 0.1\n",
            "  max_grad_norm: 0.5\n",
            "  ent_coeff: 0.001\n",
            "  ext_adv_coeff: 1.0\n",
            "  int_adv_coeff: 1.0\n",
            "  pre_normalization_steps: 10\n",
            "  predictor_proportion: 0.25\n",
            "  seed: 123\n",
            "  0% 49/10000 [00:31<1:27:47,  1.89it/s]Iter: 50 | EP: 49 | ExtR: 0.86 | Running ExtR: 0.30 | Duration: 0.21s | Time: 22:04:26\n",
            "  1% 99/10000 [00:56<1:05:10,  2.53it/s]Iter: 100 | EP: 99 | ExtR: 0.65 | Running ExtR: 0.47 | Duration: 0.66s | Time: 22:04:51\n",
            "  1% 149/10000 [01:18<1:14:51,  2.19it/s]Iter: 150 | EP: 149 | ExtR: 0.57 | Running ExtR: 0.59 | Duration: 0.85s | Time: 22:05:13\n",
            "  2% 199/10000 [01:43<1:34:05,  1.74it/s]Iter: 200 | EP: 199 | ExtR: 0.00 | Running ExtR: 0.48 | Duration: 0.49s | Time: 22:05:38\n",
            "  2% 249/10000 [02:05<1:24:39,  1.92it/s]Iter: 250 | EP: 249 | ExtR: 0.61 | Running ExtR: 0.52 | Duration: 0.43s | Time: 22:06:00\n",
            "  3% 299/10000 [02:28<1:06:33,  2.43it/s]Iter: 300 | EP: 299 | ExtR: 0.81 | Running ExtR: 0.54 | Duration: 0.48s | Time: 22:06:22\n",
            "  3% 349/10000 [02:58<1:54:34,  1.40it/s]Iter: 350 | EP: 349 | ExtR: 0.00 | Running ExtR: 0.15 | Duration: 0.95s | Time: 22:06:54\n",
            "  4% 380/10000 [03:16<2:31:19,  1.06it/s]"
          ]
        }
      ],
      "source": [
        "!python main.py --train_from_scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As19xqS3kZP4"
      },
      "source": [
        "\n",
        "## 4. Visualize Logs\n",
        "launch TensorBoard to monitor your training logs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "riwgtJAUkh56",
        "outputId": "394297b9-6dea-42a1-d167-3a127d116469"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Start Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir Logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nBRTZdHkknG"
      },
      "source": [
        "\n",
        "# End of Notebook\n",
        "# Good Luck :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}